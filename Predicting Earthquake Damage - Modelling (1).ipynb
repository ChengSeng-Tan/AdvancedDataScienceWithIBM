{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Selection, Training & Evaluation\n",
    "We will select the model which is most appropriate to predict the extent of the earthquake damage for the building characteristics defined in the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load save processed data from IBM Data Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a Spark session to start...\n",
      "Spark Initialization Done! ApplicationId = app-20191013231354-0000\n",
      "KERNEL_ID = 6f7fcb2a-9606-4984-b437-22f8709f5878\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299215</td>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>377492</td>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>294802</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>843787</td>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>343815</td>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id                                           features  label\n",
       "0       299215  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      3\n",
       "1       377492  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      1\n",
       "2       294802  (0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...      3\n",
       "3       843787  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...      3\n",
       "4       343815  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ibmos2spark\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'service_id': 'iam-ServiceId-1ffa7090-b46d-409d-a4c2-d72608483d6a',\n",
    "    'iam_service_endpoint': 'https://iam.bluemix.net/oidc/token',\n",
    "    'api_key': 'rJ9gWSE1VMXj0qVCzTfP36owXVp9NrU3vaRpVRtcgyz3'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_e69b22554ae141c3a275fabb55b0f50e_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "train_proc = spark.read.parquet(cos.url('Train_Proc.parquet', 'advanceddatasciencewithibm-donotdelete-pr-z8s5dzzkvq4bck'))\n",
    "train_proc.createOrReplaceTempView(\"train_proc\")\n",
    "\n",
    "# display first 5 rows, with scroll like in Pandas df\n",
    "train_proc.limit(5).toPandas().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260601, 3)\n"
     ]
    }
   ],
   "source": [
    "# how many rows & columns? \n",
    "print((train_proc.count(), len(train_proc.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('building_id', 'int'), ('features', 'vector'), ('label', 'int')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show column types\n",
    "train_proc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('building_id', 'int'),\n",
       " ('features', 'vector'),\n",
       " ('label', 'int'),\n",
       " ('features_sparse', 'vector')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "from pyspark.ml.linalg import Vectors, _convert_to_vector, VectorUDT\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "def dense_to_sparse(vector):\n",
    "    return _convert_to_vector(scipy.sparse.csc_matrix(vector.toArray()).T)\n",
    "\n",
    "to_sparse = udf(dense_to_sparse, VectorUDT())\n",
    "train_proc = train_proc.withColumn('features_sparse', to_sparse(col('features')))\n",
    "\n",
    "train_proc.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Training and Test Datasets\n",
    "Using 60% training and 40% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test sets\n",
    "splits = train_proc.randomSplit([0.6, 0.4])\n",
    "df_train = splits[0] # training dataset\n",
    "df_test  = splits[1]  # test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set  (156181, 4)\n",
      "Test Set  (104420, 4)\n"
     ]
    }
   ],
   "source": [
    "# how many count of training and test datasets \n",
    "print('Training Set ',(df_train.count(), len(df_train.columns)))\n",
    "print('Test Set ',(df_test.count(), len(df_test.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice of Model\n",
    "The user case is a multiclass classification and there are various algorithms available.  I select 2 Supervised Machine Learning and one Deep Learning using\n",
    "1. Logistics Regression\n",
    "2. Random Forest Classifier\n",
    "3. Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|(59,[0,3,8,11,17,...|    3|       3.0|\n",
      "|(59,[0,3,8,11,16,...|    2|       2.0|\n",
      "|(59,[0,3,9,12,16,...|    2|       2.0|\n",
      "|(59,[1,3,8,11,16,...|    2|       2.0|\n",
      "|(59,[0,5,10,13,18...|    2|       2.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "logr = LogisticRegression(featuresCol='scaledFeatures', labelCol='label',standardization=False)\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[scaler, logr])\n",
    "\n",
    "# Train model.  \n",
    "model = pipeline.fit(df_train)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(df_test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "Display the confusion matrix\n",
    "\n",
    "Evaluate the predictions using the F1 metric, which is a weighted average of precision and recall scores, which a perfect score at 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    2|       1.0| 2011|\n",
      "|    1|       3.0|  283|\n",
      "|    3|       1.0|  184|\n",
      "|    1|       2.0| 6605|\n",
      "|    2|       3.0| 5662|\n",
      "|    3|       2.0|27785|\n",
      "|    3|       3.0| 6987|\n",
      "|    2|       2.0|51735|\n",
      "|    1|       1.0| 3168|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5417550673320801"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "predictions.groupBy('label','prediction').count().show()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use F1 score as we want to focus on decreasing both false positives and false negatives.\n",
    "f1 for first logistic regression model is 0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1| 25124|\n",
      "|    3| 87218|\n",
      "|    2|148259|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at distribution of labels and see if they are balanced\n",
    "train_proc.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imbalance Handling\n",
    "The dataset is unbalanced, with Label 2 accounting for more than half (56.89%).  Label 3 occupies 33.47% while Label 1 is the smallest contributer at 9.64%.  We will rerun Logistic Regression by passing weights that will give more weightage to smaller contributers and less to bigger contributers.\n",
    "By calculations, the weights for Labels 1,2,3 are 0.4518, 0.2155 and 0.3327 respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|classWeights|\n",
      "+------------+\n",
      "|      0.2155|\n",
      "|      0.3327|\n",
      "|      0.3327|\n",
      "|      0.2155|\n",
      "|      0.2155|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_train=df_train.withColumn(\"classWeights\", when(df_train.label == 1,0.4518).when(df_train.label == 2,0.2155).otherwise(0.3327))\n",
    "\n",
    "df_train.select(\"classWeights\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|(59,[0,3,8,11,17,...|    3|       3.0|\n",
      "|(59,[0,3,8,11,16,...|    2|       2.0|\n",
      "|(59,[0,3,9,12,16,...|    2|       2.0|\n",
      "|(59,[1,3,8,11,16,...|    2|       2.0|\n",
      "|(59,[0,5,10,13,18...|    2|       2.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-run Logistic Regression with weights\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "logr = LogisticRegression(featuresCol='scaledFeatures', labelCol='label',weightCol='classWeights',standardization=False)\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[scaler, logr])\n",
    "\n",
    "# Train model.  \n",
    "model = pipeline.fit(df_train)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(df_test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    2|       1.0| 5002|\n",
      "|    1|       3.0| 1547|\n",
      "|    3|       1.0|  533|\n",
      "|    1|       2.0| 3117|\n",
      "|    2|       3.0|23449|\n",
      "|    3|       2.0|13207|\n",
      "|    3|       3.0|21216|\n",
      "|    2|       2.0|30957|\n",
      "|    1|       1.0| 5392|\n",
      "+-----+----------+-----+\n",
      "\n",
      "f1 = 0.554662\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "predictions.groupBy('label','prediction').count().show()\n",
    "\n",
    "evaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluatorf1.evaluate(predictions)\n",
    "print(\"f1 = %g\" % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score improved from 0.54 to 0.55 with class weighing technique to overcome the imbalance of label distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning\n",
    "We alter some of these pipeline parameters to see if we can improve on our F1 score from before. \n",
    "We'll set up a hyperparameter grid and do an exhaustive grid search on these hyperparameters. We start by setting up our hyperparameter grid using the ParamGridBuilder, then we determine their performance using the CrossValidator, which does k-fold cross validation (k=3 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "  .addGrid(logr.regParam, [0.01, 0.5, 2.0]) \\\n",
    "  .addGrid(logr.maxIter, [10, 20, 50]) \\\n",
    "  .addGrid(logr.elasticNetParam, [0.0, 0.5]) \\\n",
    "  .build())\n",
    "\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = crossval.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 = 0.554662\n"
     ]
    }
   ],
   "source": [
    "predictions2 = model2.transform(df_test)\n",
    "\n",
    "evaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluatorf1.evaluate(predictions)\n",
    "print(\"f1 = %g\" % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With hyperparameter tuning, the F1 score remains indicating that the default parameters have worked well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Classification using RandomForest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model for Random Forest Classifier and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|(59,[0,3,8,11,17,...|    3|       2.0|\n",
      "|(59,[0,3,8,11,16,...|    2|       2.0|\n",
      "|(59,[0,3,9,12,16,...|    2|       2.0|\n",
      "|(59,[1,3,8,11,16,...|    2|       2.0|\n",
      "|(59,[0,5,10,13,18...|    2|       2.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "# Train model.  \n",
    "model = rf.fit(df_train)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(df_test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    2|       1.0| 1497|\n",
      "|    1|       3.0|   22|\n",
      "|    3|       1.0|   66|\n",
      "|    1|       2.0| 7618|\n",
      "|    2|       3.0| 1629|\n",
      "|    3|       2.0|29827|\n",
      "|    3|       3.0| 5063|\n",
      "|    2|       2.0|56282|\n",
      "|    1|       1.0| 2416|\n",
      "+-----+----------+-----+\n",
      "\n",
      "f1 = 0.532707\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy('label','prediction').count().show()\n",
    "\n",
    "evaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluatorf1.evaluate(predictions)\n",
    "print(\"f1 = %g\" % f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score for random forest is 0.53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    3|[1.0,0.0,0.0,1.0,...|\n",
      "|    1|[1.0,0.0,0.0,1.0,...|\n",
      "|    3|[0.0,0.0,1.0,0.0,...|\n",
      "|    3|[1.0,0.0,0.0,1.0,...|\n",
      "|    3|[1.0,0.0,0.0,1.0,...|\n",
      "|    2|[0.0,0.0,1.0,1.0,...|\n",
      "|    3|[1.0,0.0,0.0,1.0,...|\n",
      "|    2|[1.0,0.0,0.0,1.0,...|\n",
      "|    3|[0.0,0.0,1.0,1.0,...|\n",
      "|    3|[1.0,0.0,0.0,1.0,...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert the data to dense vector\n",
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [r[2], Vectors.dense(r[1])]).\\\n",
    "           toDF(['label','features'])\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "data= transData(train_proc)\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class for Neural network needs to be zero-based\n",
    "data = data.withColumn('label', data.label - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[0.0,0.0,1.0,0.0,...|\n",
      "|    0|[0.0,0.0,1.0,0.0,...|\n",
      "|    0|[0.0,0.0,1.0,0.0,...|\n",
      "|    0|[0.0,0.0,1.0,0.0,...|\n",
      "|    0|[0.0,0.0,1.0,0.0,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[0.0,0.0,1.0,0.0,...|\n",
      "|    0|[0.0,0.0,1.0,0.0,...|\n",
      "|    0|[0.0,0.0,1.0,0.0,...|\n",
      "|    0|[0.0,0.0,1.0,0.0,...|\n",
      "|    0|[0.0,0.0,1.0,0.0,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split into training and test sets\n",
    "(df2_train, df2_test) = data.randomSplit([0.6, 0.4])\n",
    "\n",
    "df2_train.show(5)\n",
    "df2_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassificationModel, MultilayerPerceptronClassifier\n",
    "\n",
    "# specify layers for the neural network:\n",
    "# input layer of size 59 (features), two intermediate of size 13 and 7\n",
    "# and output of size 3 (classes)\n",
    "layers = [59, 25, 12 , 3]\n",
    "\n",
    "#scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "FNN = MultilayerPerceptronClassifier(labelCol=\"label\", \\\n",
    "                                     featuresCol=\"features\",\\\n",
    "                                     maxIter=100, layers=layers, \\\n",
    "                                     blockSize=128, seed=1234)\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[FNN])\n",
    "\n",
    "# Train model.  \n",
    "model = pipeline.fit(df2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.transform(df2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    0|       1.0| 9937|\n",
      "|    1|       1.0|59496|\n",
      "|    2|       1.0|34794|\n",
      "+-----+----------+-----+\n",
      "\n",
      "f1 = 0.414873\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy('label','prediction').count().show()\n",
    "\n",
    "evaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluatorf1.evaluate(predictions)\n",
    "print(\"f1 = %g\" % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score for Neural Networks is 0.41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best F1 score is achieved with the Logistics Regression Model with imbalance handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
